[package]
name = "llm_runner"
version = "0.1.0"
edition = "2021"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"
strip = true

[dependencies]
# LLM inference framework (Example: candle or ggml-based)
candle-core = "0.3.3"
candle-nn = "0.3.3"
candle-transformers = "0.3.3"
tokenizers = { version = "0.15", features = ["onig"] }
lazy_static = "1.4"
rayon = "1.8"
dirs = "5.0"

# FFI for Dart bindings
jni = "0.21.0"

# Async + HTTP for downloading models
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.11", features = ["blocking", "json"] }
serde_json = "1.0"
serde = { version = "1.0", features = ["derive"] }

# Hugging Face Hub
hf-hub = "0.3.2"

[build-dependencies]
cbindgen = "0.26.0"

[lib]
crate-type = ["cdylib"]  # Make it compatible with Flutter/Dart FFI
